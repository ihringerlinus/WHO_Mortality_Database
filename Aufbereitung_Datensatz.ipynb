{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfe0e62",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "## In this section, we will prepare your data for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8b819",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54cfcb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa122a",
   "metadata": {},
   "source": [
    "#### Concatenation of the csv files\n",
    "##### Our data was split into 6 different csv files. In this section we are concatenating all these files into one single csv file(base_data.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a1285e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5143931, 39)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(\"Data_Files/Morticd10_part*.csv\")\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f, low_memory=False)\n",
    "    dfs.append(df)\n",
    "merged = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "merged.shape\n",
    "\n",
    "##merged.to_csv(\"Data_Files/base_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22d0a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['101', '103', '104', 'UE1', 101, 103, 104, '10M'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['List'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "901a7ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2016    21340\n",
       "2014    19957\n",
       "2013    18514\n",
       "2015    18196\n",
       "2017    17899\n",
       "2008    17638\n",
       "2005    16706\n",
       "2012    15654\n",
       "2011    15603\n",
       "2004    15284\n",
       "2007    15187\n",
       "2019    14797\n",
       "2009    14779\n",
       "2006    14744\n",
       "2010    14711\n",
       "2000    14177\n",
       "2018    13647\n",
       "2001    13258\n",
       "2003    12549\n",
       "2002    12461\n",
       "1998    12449\n",
       "1999    11416\n",
       "2020     9338\n",
       "1997     7930\n",
       "1996     6930\n",
       "2022     5437\n",
       "2021     4981\n",
       "1995     3011\n",
       "2023     2966\n",
       "1994     1978\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[\"List\"].value_counts()\n",
    "merged[\"Year\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc10374d",
   "metadata": {},
   "source": [
    "#### Deletion of unnecessary rows\n",
    "##### In this section we are deleting all the rows that are not necessary for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93b6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged[(merged[\"List\"] == 103) | (merged[\"List\"] == '103')]\n",
    "\n",
    "data.to_csv(\"Data_Files/base_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f45954",
   "metadata": {},
   "source": [
    "#### Lookup Country Names\n",
    "##### In this section we are looking up the country names based on the country codes provided in the dataset (country_codes.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9302fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/37/084722ds0s5f0lsp5b75z_w40000gn/T/ipykernel_64009/1868936303.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mortality = pd.read_csv(r\"Data_Files/base_data.csv\", encoding=\"utf-8-sig\")\n"
     ]
    }
   ],
   "source": [
    "codes = pd.read_csv(\"codes_Files/country_codes.csv\", encoding=\"utf-8-sig\")\n",
    "mortality = pd.read_csv(r\"Data_Files/base_data.csv\", encoding=\"utf-8-sig\")\n",
    "merged = mortality.merge(codes, left_on=\"Country\", right_on=\"country\", how=\"left\")\n",
    "merged[\"Country\"] = merged[\"name\"]\n",
    "merged = merged.drop(columns=[\"country\", \"name\"])\n",
    "merged.to_csv(\"Data_Files/mortality_with_country_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38895198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/37/084722ds0s5f0lsp5b75z_w40000gn/T/ipykernel_64009/461549012.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset = pd.read_csv(\"Data_Files/mortality_with_country_names.csv\")\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Data_Files/mortality_with_country_names.csv\")\n",
    "dataset = dataset.drop(df.columns[[1, 2]], axis=1)\n",
    "\n",
    "# save the result\n",
    "dataset.to_csv(\"Data_Files/mortality_clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
